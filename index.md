---
layout: default
---
# Welcome!
<div class="index-content">

I am a PhD candidate in Computer Science (AI/NLP) at Colorado State University, working with [Dr. Nikhil Krishnaswamy](https://www.nikhilkrishnaswamy.com/) at the [SIGNAL Lab](https://www.signallab.ai/people). During the summer and fall of 2024, I worked with [Optum AI](https://www.optumlabs.com/work/artificial-intelligence.html) on their LLM-alignment team, focusing on efficient preference alignment for healthcare applications. I am currently seeking Full-Time Research Scientist or Machine Learning Engineer positions and internships.

# My Research
What happens when AI begins to truly understand and align with human intentions? That's the question I aim to answer. I specialize in developing next-generation generative AI systems (LLMs) that are not only intelligent but also deeply aligned with human values. My work includes aligning summaries of doctor-patient interactions and designing AI "thought-partners" for enhanced collaboration, with a focus on safety, alignment, and usability. 

Most users today experience "frictionless" interactions with LLMs, but my research explores training and aligning "frictive agents"‚ÄîLLMs that can cross-examine and track ToM-based (Theory of Mind) beliefs in multi-user settings. I also led the development of **[AxomiyaBERTa](https://aclanthology.org/2023.findings-acl.739/)**, the first monolingual Assamese transformer-based language model, setting benchmarks for low-resource language processing by leveraging Assamese-specific phonological signals in transfer learning.

## News
- üéâ **Best Paper Award** at Educational Data Mining (EDM) 2024
- üéì **Received PhD Candidacy** with Distinction, December 2024
- üèÜ **Awarded Evolutionary Computing and AI Graduate Fellowship**, 2024
- üìù **Paper accepted at NAACL 2024** (Oral)
- üìù **Paper accepted at Findings of EMNLP 2024**
- üìù **Paper accepted at LREC-COLING 2024**

## Selected Publications

* **[Simultaneous Reward Distillation and Preference Learning: Get You a Language Model Who Can Do Both](https://arxiv.org/pdf/2410.08458)**  
  *Under Review*  
  A novel approach to combining reward learning with preference optimization in language models.

* **[DPL: Diverse Preference Learning Without A Reference Model](https://drive.google.com/file/d/1dFI_N0zgXF4YkawaIJqqoyEKn2IU9xEO/view?usp=sharing)**  
  *Under Review*  
  Pioneering work on preference learning that eliminates the need for reference models while maintaining diversity.

* **[Okay, Let's Do This! Modeling Event Coreference with Generated Rationales](https://arxiv.org/pdf/2404.03196.pdf)** üèÜ  
  *NAACL 2024 (Oral)*  
  Novel approach to event coreference using LLM-generated rationales and knowledge distillation.  
  [Code](https://github.com/csu-signal/llama_cdcr)

* **["Any Other Thoughts, Hedgehog?" Linking Deliberation Chains](https://www.nikhilkrishnaswamy.com/assets/docs/pdfs/EMNLP-2024-Nath.pdf)** ‚≠ê  
  *Findings of EMNLP 2024*  
  Proposed a novel task of linking reasoning chains in multi-agent collaborative dialogues.  
  [Code](https://github.com/csu-signal/ProbingDelibration)

[View all publications ‚Üí](publications)


## Quick Links
- [Publications](publications.md)
- [Curriculum Vitae](Nath_CV_Jan2025.pdf)
- [Google Scholar](https://scholar.google.com/citations?user=J9FdsyYAAAAJ&hl=en)
- [GitHub](https://github.com/AbhijnanNath)
- [LinkedIn](https://linkedin.com/in/abhijnan-nath-737727169)
- [YouTube Channel](https://www.youtube.com/@avign5291)

## Contact
Email: abhijnan.nath@colostate.edu  
Department of Computer Science  
Colorado State University  
Fort Collins, CO 80523

</div>
