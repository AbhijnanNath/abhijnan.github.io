---
layout: default
---
# Welcome!
 
I am a PhD candidate in Computer Science (AI/NLP) at Colorado State University, working with [Dr. Nikhil Krishnaswamy](https://www.nikhilkrishnaswamy.com/) at the [SIGNAL Lab](https://www.signallab.ai/people). In the summer and fall of 2024, I worked with [Optum AI](https://www.optumlabs.com/work/artificial-intelligence.html) on their LLM-alignment team, focusing on efficient preference alignment for healthcare applications. **I am currently looking for Full-Time Research Scientist/Machine Learning Engineer positions and internships.**

# My Research
What happens when AI begins to truly understand and align with human intentions? That's the question I aim to answer. I specialize in developing next-generation generative AI systems (or LLMs) that are not only intelligent but also deeply aligned with human values. My work spans aligning summaries of doctor-patient interactions to designing AI "thought-partners" for enhanced collaboration, with a focus on safety, alignment, and usability. For example, most users these days have a "frictionless" experience using LLMs---but my research asks the question of whether it is possible to train and align ‚Äúfrictive agents‚Äù---LLMs that can cross-examine and track ToM-based beliefs in multi-user settings. I led the development of **[AxomiyaBERTa](https://aclanthology.org/2023.findings-acl.739/)**, the *first* monolingual Assamese transformer-based language model, which set new benchmarks for low-resource language processing by leveraging Assamese-specific phonological signals in transfer learning.

## News
- Feb' 25: Presented my research on ‚ÄúFriction‚Äù Agents at DARPA's Friction and Accountability in Conversational Transactions (FACT) PI Meeting in Stanford University!
- Jan' 25 üìù Paper on Diverse Preference Learning (DPL) in LLMs accepted at NAACL 2025 Main Conference! 
- üéâ Best Paper Award at Educational Data Mining (EDM) 2024
- üéì Received PhD Candidacy with Distinction, December 2024
- üèÜ Awarded Evolutionary Computing and AI Graduate Fellowship 2024
- üìù Paper accepted at NAACL 2024 (Oral)
- üìù Paper accepted at Findings of EMNLP 2024
- üìù Paper accepted at LREC-COLING 2024


## Selected Publications

* **[Simultaneous Reward Distillation and Preference Learning: Get You a Language Model Who Can Do Both](https://arxiv.org/pdf/2410.08458)**  
  *Under Review*  
  A novel approach to combining reward learning with preference optimization in language models.

* **[DPL: Diverse Preference Learning Without A Reference Model](https://drive.google.com/file/d/1N0vDYeeHic2dbISrtJAZfkYKmORTZNz2/view?usp=sharing)**  
  *NAACL Main 2025*  
  Pioneering work on preference learning that eliminates the need for reference models while maintaining diversity.

* **[Okay, Let's Do This! Modeling Event Coreference with Generated Rationales](https://arxiv.org/pdf/2404.03196.pdf)** üèÜ  
  *NAACL 2024 (Oral)*  
  Novel approach to event coreference using LLM-generated rationales and knowledge distillation.  
  [Code](https://github.com/csu-signal/llama_cdcr)

* **["Any Other Thoughts, Hedgehog?" Linking Deliberation Chains](https://www.nikhilkrishnaswamy.com/assets/docs/pdfs/EMNLP-2024-Nath.pdf)** ‚≠ê  
  *Findings of EMNLP 2024*  
  Proposed a novel task of linking reasoning chains in multi-agent collaborative dialogues.  
  [Code](https://github.com/csu-signal/ProbingDelibration)

[View all publications ‚Üí](publications)


## Quick Links
- [Publications](publications.md)
- [Curriculum Vitae](Nath_CV_Jan2025.pdf)
- [Research Statement](nath_research_statement_2025_website.pdf)
- [Google Scholar](https://scholar.google.com/citations?user=J9FdsyYAAAAJ&hl=en)
- [GitHub](https://github.com/AbhijnanNath)
- [LinkedIn](https://linkedin.com/in/abhijnan-nath-737727169)
- [Youtube Channel](https://www.youtube.com/@avign5291)

## Contact
Email: abhijnan.nath@colostate.edu  
Department of Computer Science  
Colorado State University  
Fort Collins, CO 80523
