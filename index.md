---
layout: default
---
# Welcome!
I am a PhD student in Computer Science (AI/NLP) at Colorado State University, working with [Dr. Nikhil Krishnaswamy](https://www.nikhilkrishnaswamy.com/). 
 
What happens when AI begins to truly understand and align with human intentions? That's the question I aim to answer. I specialize in developing next-generation generative AI systems that are not only intelligent but also deeply aligned with human values. My work spans aligning summaries of doctor-patient interactions to designing AI "thought-partners" for enhanced collaboration, with a focus on safety, alignment, and usability. By combining rigorous alignment methodologies with an emphasis on human-centric design, I strive to create systems that are efficient, trustworthy, and accessible.

## News
- üéâ Best Paper Award at Educational Data Mining (EDM) 2024
- üéì Received PhD Candidacy with Distinction, December 2024
- üèÜ Awarded Evolutionary Computing and AI Graduate Fellowship 2024
- üìù Paper accepted at NAACL 2024 (Oral)
- üìù Paper accepted at LREC-COLING 2024


## Selected Publications

* **[Simultaneous Reward Distillation and Preference Learning: Get You a Language Model Who Can Do Both](https://arxiv.org/pdf/2410.08458)**  
  *Under Review*  
  A novel approach to combining reward learning with preference optimization in language models.

* **[DPL: Diverse Preference Learning Without A Reference Model](https://drive.google.com/file/d/1dFI_N0zgXF4YkawaIJqqoyEKn2IU9xEO/view?usp=sharing)**  
  *Under Review*  
  Pioneering work on preference learning that eliminates the need for reference models while maintaining diversity.

* **[Okay, Let's Do This! Modeling Event Coreference with Generated Rationales](https://arxiv.org/pdf/2404.03196.pdf)** üèÜ  
  *NAACL 2024 (Oral)*  
  Novel approach to event coreference using LLM-generated rationales and knowledge distillation.  
  [[Code](https://github.com/csu-signal/llama_cdcr)]

* **["Any Other Thoughts, Hedgehog?" Linking Deliberation Chains](https://www.nikhilkrishnaswamy.com/assets/docs/pdfs/EMNLP-2024-Nath.pdf)** ‚≠ê  
  *Findings of EMNLP 2024*  
  Proposed a novel task of linking reasoning chains in multi-agent collaborative dialogues.  
  [[Code](https://github.com/csu-signal/ProbingDelibration)]

[View all publications ‚Üí](publications)

## Quick Links
- [Publications](publications.md)
- [Curriculum Vitae](Nath_CV_Jan2025.pdf)
- [Google Scholar](https://scholar.google.com/citations?user=J9FdsyYAAAAJ&hl=en)
- [GitHub](https://github.com/AbhijnanNath)
- [LinkedIn](https://linkedin.com/in/abhijnan-nath-737727169)
- [Youtube Channel](https://linkedin.com/in/abhijnan-nath-737727169)

## Contact
Email: abhijnan.nath@colostate.edu  
Department of Computer Science  
Colorado State University  
Fort Collins, CO 80523